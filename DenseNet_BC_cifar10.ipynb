{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenseNet-BC cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MyWhiteCastle/BME-Project2/blob/master/DenseNet_BC_cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiFxPn-QVKg2",
        "colab_type": "code",
        "outputId": "76979085-8b04-4b07-f205-0f9dc98fc156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# packages preloading\n",
        "## packages for dataset and image preprocessing\n",
        "from tensorflow.keras.datasets import cifar10,cifar100\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "## packages for modeling\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "import math\n",
        "\n",
        "## visualization & file saving\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle \n",
        "\n",
        "## version checking\n",
        "print (tf.keras.__version__)\n",
        "print (tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.4-tf\n",
            "1.15.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh7YhVcAZQF9",
        "colab_type": "text"
      },
      "source": [
        "#Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8Rc9C2-saqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for data augmentation\n",
        "def getDataGenerator(train_phase):\n",
        "    if train_phase == True:\n",
        "        datagen = ImageDataGenerator(\n",
        "        rotation_range=0.,\n",
        "        width_shift_range=0.05,\n",
        "        height_shift_range=0.05,\n",
        "        shear_range=0.05,\n",
        "        zoom_range=0.05,\n",
        "        channel_shift_range=0.,\n",
        "        fill_mode='nearest',\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=False,\n",
        "        rescale=None)\n",
        "    else: \n",
        "        datagen = ImageDataGenerator(\n",
        "        rescale=None\n",
        "        )\n",
        "\n",
        "    return datagen\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2n5V_MqO96CE",
        "colab_type": "text"
      },
      "source": [
        "## - Cifar10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz9cz7MlsigE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define DenseNet parms Cifar10\n",
        "nb_classes = 10\n",
        "img_dim = (32,32,3)\n",
        "\n",
        "batch_size = 64\n",
        "nb_epoch = 40"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CSeUfStZPgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# datasets with data augmentation\n",
        "(x_train,y_train),(x_test,y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "y_train = keras.utils.to_categorical(y_train, nb_classes)\n",
        "y_test= keras.utils.to_categorical(y_test, nb_classes)\n",
        "\n",
        "# hold out 5000 samples from training for validation\n",
        "x_tr,x_val,y_tr,y_val = train_test_split(x_train,y_train,test_size=0.1, random_state=42)\n",
        "\n",
        "train_datagen = getDataGenerator(train_phase=True)\n",
        "train_datagen = train_datagen.flow(x_train,y_train,batch_size = batch_size)\n",
        "\n",
        "validation_datagen = getDataGenerator(train_phase=False)\n",
        "validation_datagen = validation_datagen.flow(x_val,y_val,batch_size = batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBrv3JHp_NJ3",
        "colab_type": "code",
        "outputId": "d2c32ec9-56bf-4433-91e2-f18559dcfec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# dataset without data augmentation\n",
        "(x_train,y_train),(x_test,y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "y_train = keras.utils.to_categorical(y_train, nb_classes)\n",
        "y_test= keras.utils.to_categorical(y_test, nb_classes)\n",
        "\n",
        "# hold out 5000 samples from training for validation\n",
        "x_tr,x_val,y_tr,y_val = train_test_split(x_train,y_train,test_size=0.1, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qbTSDH7bwQN",
        "colab_type": "code",
        "outputId": "a8463033-4643-4bce-a861-3b2ea76e4671",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print(x_train.shape,y_train.shape)\n",
        "print(x_tr.shape,y_tr.shape)\n",
        "print(x_val.shape,y_val.shape)\n",
        "print(x_test.shape,y_test.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3) (50000, 10)\n",
            "(45000, 32, 32, 3) (45000, 10)\n",
            "(5000, 32, 32, 3) (5000, 10)\n",
            "(10000, 32, 32, 3) (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aKVl68F9t8H",
        "colab_type": "text"
      },
      "source": [
        "## - Cifar100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JHYenFH9_sU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define DenseNet parms Cifar10\n",
        "nb_classes = 100\n",
        "img_dim = (32,32,3)\n",
        "\n",
        "batch_size = 64\n",
        "nb_epoch = 40"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVSlrB859w_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# datasets with data augmentation\n",
        "(x_train,y_train),(x_test,y_test) = cifar100.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "y_train = keras.utils.to_categorical(y_train, nb_classes)\n",
        "y_test= keras.utils.to_categorical(y_test, nb_classes)\n",
        "\n",
        "# hold out 5000 samples from training for validation\n",
        "x_tr,x_val,y_tr,y_val = train_test_split(x_train,y_train,test_size=0.1, random_state=42)\n",
        "\n",
        "train_datagen = getDataGenerator(train_phase=True)\n",
        "train_datagen = train_datagen.flow(x_train,y_train,batch_size = batch_size)\n",
        "\n",
        "validation_datagen = getDataGenerator(train_phase=False)\n",
        "validation_datagen = validation_datagen.flow(x_val,y_val,batch_size = batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnIda1ZY-xX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# datasets without data augmentation\n",
        "(x_train,y_train),(x_test,y_test) = cifar100.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "y_train = keras.utils.to_categorical(y_train, nb_classes)\n",
        "y_test= keras.utils.to_categorical(y_test, nb_classes)\n",
        "\n",
        "# hold out 5000 samples from training for validation\n",
        "x_tr,x_val,y_tr,y_val = train_test_split(x_train,y_train,test_size=0.1, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEyOf-gt99lN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x_train.shape,y_train.shape)\n",
        "print(x_tr.shape,y_tr.shape)\n",
        "print(x_val.shape,y_val.shape)\n",
        "print(x_test.shape,y_test.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFmcxrXacsRC",
        "colab_type": "text"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwlKUw-q1Plb",
        "colab_type": "text"
      },
      "source": [
        "## Model Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4AIWqbP4lI2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define chuncks of model \n",
        "def conv_layer(inputs,filters,kernel_size,strides,dropout_rate=None,weight_decay=1E-4):\n",
        "    \"\"\"single convolution 2D with pre-activation\"\"\"\n",
        "  \n",
        "    ## pre-activation BN and ReLU\n",
        "    bn_axis = 1 if K.image_data_format() == \"th\" else -1\n",
        "  \n",
        "    x = layers.BatchNormalization(axis = bn_axis, epsilon=1.1e-5)(inputs)\n",
        "    x = layers.Activation('relu')(x)\n",
        "  \n",
        "    ## conv2D layer with padding = 'same'\n",
        "    outputs = layers.Conv2D(filters = filters, kernel_size = kernel_size,strides = strides, \n",
        "                            kernel_initializer=\"he_uniform\", padding = 'same', use_bias=False,\n",
        "                            kernel_regularizer = regularizers.l2(weight_decay))(x)\n",
        "  \n",
        "    ## dropout layer after convolutional layers except the first conv layer (for dataset without data augmentation)\n",
        "    if dropout_rate is not None: \n",
        "        outputs = layers.Dropout(dropout_rate)(outputs)\n",
        "  \n",
        "    return outputs\n",
        "\n",
        "def bottleneck_layer(inputs,filters):\n",
        "    \"\"\"bottleneck layer with pre-activation\"\"\"\n",
        "    ## pre-activation BN and ReLU\n",
        "    bn_axis = 1 if K.image_data_format() == \"th\" else -1\n",
        "  \n",
        "    x = layers.BatchNormalization(axis = bn_axis, epsilon=1.1e-5)(inputs)\n",
        "    x = layers.Activation('relu')(x)\n",
        "  \n",
        "    ## conv2D layer with kernel size 1 x 1\n",
        "    ### number of feature maps of bottleneck layer = 4k \n",
        "    nb_filter = 4 * filters\n",
        "    outputs = layers.Conv2D(filters = nb_filter, kernel_size = (1,1),strides = (1,1), padding = 'same')(x)\n",
        "  \n",
        "    return outputs  \n",
        "\n",
        "def conv_block(inputs,filters):\n",
        "    \"\"\"conv block consisting of a bottleneck layer and a convolution layer with kernel size 3x3\"\"\"\n",
        "  \n",
        "    kernel_size = (3,3)\n",
        "    strides = (1,1)\n",
        "  \n",
        "    x = bottleneck_layer(inputs,filters)\n",
        "    outputs = conv_layer(x,filters,kernel_size,strides)\n",
        "    \n",
        "  \n",
        "    return outputs\n",
        "\n",
        "def dense_block(inputs,nb_filter,growth_rate, nb_conv_block):\n",
        "    \"\"\"a convolutional block with multiple conv blocks and concatenation for outputs of each conv block \n",
        "       key innovation for DenseNet\n",
        "    \"\"\"\n",
        "    concat_axis = 1 if K.image_data_format() == \"th\" else -1\n",
        "\n",
        "    # x_list is created for storage purpose\n",
        "    x_list = [inputs]\n",
        "  \n",
        "    for i in range(nb_conv_block):\n",
        "        outputs = conv_block(inputs, growth_rate)\n",
        "        x_list.append(outputs)\n",
        "        inputs = layers.concatenate([inputs,outputs],concat_axis)\n",
        "    \n",
        "        nb_filter +=growth_rate\n",
        "\n",
        "    return inputs,nb_filter,x_list\n",
        "\n",
        "def transition_block(inputs,nb_filter,theta,dropout_rate):\n",
        "    \"\"\"a block that consists of one bottleneck conv layer and a pooling layer\n",
        "       to furhter improve model compactness\n",
        "    \"\"\"\n",
        "    \n",
        "    #compression parameter to reduce number of channels/filters\n",
        "    ## theta = 1 for no compression\n",
        "    ## theta = 0.5 for DenseNet-BC\n",
        "  \n",
        "    x = conv_layer(inputs,math.floor(nb_filter * theta),(1,1),(1,1),dropout_rate)\n",
        "    x = layers.AveragePooling2D((2, 2), strides=(2, 2))(x)\n",
        "  \n",
        "    return x, math.floor(nb_filter * theta)\n",
        "\n",
        "# define the model \n",
        "def DenseNet(inputs,init_nb_filters,growth_rate,nb_layers,theta,dropout_rate,weight_decay):\n",
        "    \"\"\"the actual DenseNet model\"\"\"\n",
        "    ## The initial convolution layer comprises 2k convolutions of size 3 x 3 with stride 1\n",
        "    x = conv_layer(inputs,init_nb_filters,(3,3),(1,1))\n",
        "\n",
        "    ## Dense Block (1) + Transition Block (1)\n",
        "    x,nb_filters,x_list_ = dense_block(x,init_nb_filters,growth_rate,nb_layers)\n",
        "    x,nb_filters = transition_block(x, nb_filters,theta, dropout_rate)\n",
        "\n",
        "    ## Dense Block (2) + Transition Block (2)\n",
        "    x,nb_filters,x_list_ = dense_block(x,nb_filters,growth_rate,nb_layers)\n",
        "    x,nb_filters = transition_block(x, nb_filters,theta, dropout_rate)\n",
        "\n",
        "    ## Dense Block (3)\n",
        "    x,nb_filters,x_list_ = dense_block(x,nb_filters,growth_rate,nb_layers)\n",
        "\n",
        "    ## Global Average Pooling \n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    ## FC classification layer\n",
        "    x = layers.Dense(nb_classes, activation='softmax', kernel_regularizer=regularizers.l2(weight_decay), bias_regularizer=regularizers.l2(weight_decay))(x)\n",
        "\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbLrVU3o1eLt",
        "colab_type": "text"
      },
      "source": [
        "## Model Hyperparamters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZnC6DrEPMEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hyperparameters\n",
        "## growth rate =k \n",
        "growth_rate = 12\n",
        "\n",
        "\n",
        "## initial number of output channels\n",
        "### DenseNet-B: 16\n",
        "### DenseNet-BC: 2 * growth_rate\n",
        "init_nb_filters = 24\n",
        "\n",
        "\n",
        "## same number of layers in each dense block\n",
        "depth = 40\n",
        "nb_layers = 16\n",
        "\n",
        "\n",
        "## dropout rate \n",
        "### DenseNet with data augmentation\n",
        "dropout_rate = None\n",
        "### DenseNet without data augmentation\n",
        "### dropout_rate = 0.2\n",
        "\n",
        "## weight decay \n",
        "weight_decay=1E-4\n",
        "\n",
        "## theta \n",
        "theta = 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IGq8hMT1j3i",
        "colab_type": "text"
      },
      "source": [
        "## Model Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDZAZYZraS9h",
        "colab_type": "text"
      },
      "source": [
        "### DenseNet-BC-100-12 with data augmentation\n",
        "- dropout_rate = None\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz5GEpjhaVLX",
        "colab_type": "code",
        "outputId": "7d9680a2-74e0-4b60-f3b5-e9884bc242a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# DenseNet-BC setup\n",
        "\n",
        "## input images 32 x 32\n",
        "inputs = keras.Input(img_dim)\n",
        "\n",
        "## call DenseNet-BC-100-12 with data augmentation\n",
        "outputs = DenseNet(inputs,init_nb_filters,growth_rate,nb_layers,theta,dropout_rate,weight_decay)\n",
        "\n",
        "## assign the actual model\n",
        "model = keras.Model(inputs,outputs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACfs-bIl3vvN",
        "colab_type": "code",
        "outputId": "3028a05b-4248-4ae5-a869-08dd46d42cad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 3)    12          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 3)    0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 24)   648         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 24)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 24)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 48)   1200        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 48)   192         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 48)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 12)   5184        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 36)   0           conv2d[0][0]                     \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 36)   144         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 36)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 48)   1776        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 48)   192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 48)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 12)   5184        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 48)   0           concatenate[0][0]                \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 48)   192         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 48)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 48)   2352        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 48)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 12)   5184        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 60)   0           concatenate_1[0][0]              \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 60)   240         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 60)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 48)   2928        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 48)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 48)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 12)   5184        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 72)   0           concatenate_2[0][0]              \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 72)   288         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 72)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 48)   3504        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 48)   192         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 48)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 12)   5184        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 84)   0           concatenate_3[0][0]              \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 84)   336         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 84)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 48)   4080        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 48)   192         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 48)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 12)   5184        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 96)   0           concatenate_4[0][0]              \n",
            "                                                                 conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 96)   384         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 96)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 48)   4656        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 48)   192         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 32, 48)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 12)   5184        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 108)  0           concatenate_5[0][0]              \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 32, 108)  432         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 32, 32, 108)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 48)   5232        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 32, 32, 48)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 32, 32, 48)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 12)   5184        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 32, 32, 120)  0           concatenate_6[0][0]              \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 32, 32, 120)  480         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 32, 32, 120)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 48)   5808        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 32, 32, 48)   192         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 32, 32, 48)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 12)   5184        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 132)  0           concatenate_7[0][0]              \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 32, 32, 132)  528         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 32, 32, 132)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 48)   6384        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 32, 32, 48)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 32, 32, 12)   5184        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 32, 144)  0           concatenate_8[0][0]              \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 32, 32, 144)  576         concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 32, 32, 144)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 32, 32, 48)   6960        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 32, 32, 48)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 32, 32, 48)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 32, 32, 12)   5184        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 32, 32, 156)  0           concatenate_9[0][0]              \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 32, 32, 156)  624         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 32, 32, 156)  0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 32, 32, 48)   7536        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 32, 32, 48)   192         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 32, 32, 48)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 32, 32, 12)   5184        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 32, 32, 168)  0           concatenate_10[0][0]             \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 32, 32, 168)  672         concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 32, 32, 168)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 32, 32, 48)   8112        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 32, 32, 48)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 32, 32, 48)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 32, 32, 12)   5184        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 32, 32, 180)  0           concatenate_11[0][0]             \n",
            "                                                                 conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 32, 32, 180)  720         concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 32, 32, 180)  0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 32, 32, 48)   8688        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 32, 32, 48)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 32, 32, 48)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 32, 32, 12)   5184        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 32, 32, 192)  0           concatenate_12[0][0]             \n",
            "                                                                 conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 32, 32, 192)  768         concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 32, 32, 192)  0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 32, 32, 48)   9264        activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 32, 32, 48)   192         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 32, 32, 48)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 32, 32, 12)   5184        activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 32, 32, 204)  0           concatenate_13[0][0]             \n",
            "                                                                 conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 32, 32, 204)  816         concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 32, 32, 204)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 32, 32, 48)   9840        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 32, 32, 48)   192         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 32, 32, 48)   0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 32, 32, 12)   5184        activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 32, 32, 216)  0           concatenate_14[0][0]             \n",
            "                                                                 conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 32, 32, 216)  864         concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 32, 32, 216)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 32, 32, 108)  23328       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 108)  0           conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 16, 16, 108)  432         average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 16, 16, 108)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 16, 16, 48)   5232        activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 16, 16, 48)   192         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 16, 16, 48)   0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 16, 16, 12)   5184        activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 16, 16, 120)  0           average_pooling2d[0][0]          \n",
            "                                                                 conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 16, 16, 120)  480         concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 16, 16, 120)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 16, 16, 48)   5808        activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 16, 16, 48)   192         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 16, 16, 48)   0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 16, 16, 12)   5184        activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 16, 16, 132)  0           concatenate_16[0][0]             \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 16, 16, 132)  528         concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 16, 16, 132)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 16, 16, 48)   6384        activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 16, 16, 48)   192         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 16, 16, 48)   0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 16, 16, 12)   5184        activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 16, 16, 144)  0           concatenate_17[0][0]             \n",
            "                                                                 conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 16, 16, 144)  576         concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 16, 16, 144)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 16, 16, 48)   6960        activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 16, 16, 48)   192         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 16, 16, 48)   0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 16, 16, 12)   5184        activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 16, 16, 156)  0           concatenate_18[0][0]             \n",
            "                                                                 conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 16, 16, 156)  624         concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 16, 16, 156)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 16, 16, 48)   7536        activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 16, 16, 48)   192         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 16, 16, 48)   0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 16, 16, 12)   5184        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 16, 16, 168)  0           concatenate_19[0][0]             \n",
            "                                                                 conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 16, 16, 168)  672         concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 16, 16, 168)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 16, 16, 48)   8112        activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 16, 16, 48)   192         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 16, 16, 48)   0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 16, 16, 12)   5184        activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 16, 16, 180)  0           concatenate_20[0][0]             \n",
            "                                                                 conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 16, 16, 180)  720         concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 16, 16, 180)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 16, 16, 48)   8688        activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 16, 16, 48)   192         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 16, 16, 48)   0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 16, 16, 12)   5184        activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 16, 16, 192)  0           concatenate_21[0][0]             \n",
            "                                                                 conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 16, 16, 192)  768         concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 16, 16, 192)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 16, 16, 48)   9264        activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 16, 16, 48)   192         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 16, 16, 48)   0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 16, 16, 12)   5184        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 16, 16, 204)  0           concatenate_22[0][0]             \n",
            "                                                                 conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 16, 16, 204)  816         concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 16, 16, 204)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 16, 16, 48)   9840        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 16, 16, 48)   192         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 16, 16, 48)   0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 16, 16, 12)   5184        activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 16, 16, 216)  0           concatenate_23[0][0]             \n",
            "                                                                 conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 16, 16, 216)  864         concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 16, 16, 216)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 16, 16, 48)   10416       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 16, 16, 48)   192         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 16, 16, 48)   0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 16, 16, 12)   5184        activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 16, 16, 228)  0           concatenate_24[0][0]             \n",
            "                                                                 conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 16, 16, 228)  912         concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 16, 16, 228)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 16, 16, 48)   10992       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 16, 16, 48)   192         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 16, 16, 48)   0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 16, 16, 12)   5184        activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 16, 16, 240)  0           concatenate_25[0][0]             \n",
            "                                                                 conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 16, 16, 240)  960         concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 16, 16, 240)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 16, 16, 48)   11568       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 16, 16, 48)   192         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 16, 16, 48)   0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 16, 16, 12)   5184        activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 16, 16, 252)  0           concatenate_26[0][0]             \n",
            "                                                                 conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 16, 16, 252)  1008        concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 16, 16, 252)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 16, 16, 48)   12144       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 16, 16, 48)   192         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 16, 16, 48)   0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 16, 16, 12)   5184        activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 16, 16, 264)  0           concatenate_27[0][0]             \n",
            "                                                                 conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 16, 16, 264)  1056        concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 16, 16, 264)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 16, 16, 48)   12720       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 16, 16, 48)   192         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 16, 16, 48)   0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 16, 16, 12)   5184        activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 16, 16, 276)  0           concatenate_28[0][0]             \n",
            "                                                                 conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 16, 16, 276)  1104        concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 16, 16, 276)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 16, 16, 48)   13296       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 16, 16, 48)   192         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 16, 16, 48)   0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 16, 16, 12)   5184        activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 16, 16, 288)  0           concatenate_29[0][0]             \n",
            "                                                                 conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 16, 16, 288)  1152        concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 16, 16, 288)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 16, 16, 48)   13872       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 16, 16, 48)   192         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 16, 16, 48)   0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 16, 16, 12)   5184        activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 16, 16, 300)  0           concatenate_30[0][0]             \n",
            "                                                                 conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 16, 16, 300)  1200        concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 16, 16, 300)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 16, 16, 150)  45000       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 8, 8, 150)    0           conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 8, 8, 150)    600         average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 8, 8, 150)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 8, 8, 48)     7248        activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 8, 8, 48)     192         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 8, 8, 48)     0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 8, 8, 12)     5184        activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 8, 8, 162)    0           average_pooling2d_1[0][0]        \n",
            "                                                                 conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 8, 8, 162)    648         concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 8, 8, 162)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 8, 8, 48)     7824        activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 8, 8, 48)     192         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 8, 8, 48)     0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 8, 8, 12)     5184        activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 8, 8, 174)    0           concatenate_32[0][0]             \n",
            "                                                                 conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 8, 8, 174)    696         concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 174)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 8, 8, 48)     8400        activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 8, 8, 48)     192         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 8, 8, 48)     0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 8, 8, 12)     5184        activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 8, 8, 186)    0           concatenate_33[0][0]             \n",
            "                                                                 conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 8, 8, 186)    744         concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 8, 8, 186)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 8, 8, 48)     8976        activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 8, 8, 48)     192         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 8, 8, 48)     0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 8, 8, 12)     5184        activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 8, 8, 198)    0           concatenate_34[0][0]             \n",
            "                                                                 conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 8, 8, 198)    792         concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 8, 8, 198)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 8, 8, 48)     9552        activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 8, 8, 48)     192         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 48)     0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 12)     5184        activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 8, 8, 210)    0           concatenate_35[0][0]             \n",
            "                                                                 conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 8, 8, 210)    840         concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 210)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 48)     10128       activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 8, 8, 48)     192         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 8, 8, 48)     0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 12)     5184        activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 8, 8, 222)    0           concatenate_36[0][0]             \n",
            "                                                                 conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 8, 8, 222)    888         concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 8, 8, 222)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 48)     10704       activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 8, 8, 48)     192         conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 8, 8, 48)     0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 12)     5184        activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 8, 8, 234)    0           concatenate_37[0][0]             \n",
            "                                                                 conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 8, 8, 234)    936         concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 8, 8, 234)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 48)     11280       activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 8, 8, 48)     192         conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 8, 8, 48)     0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 12)     5184        activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 8, 8, 246)    0           concatenate_38[0][0]             \n",
            "                                                                 conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 8, 8, 246)    984         concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 8, 8, 246)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 48)     11856       activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 8, 8, 48)     192         conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 8, 8, 48)     0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 12)     5184        activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 8, 8, 258)    0           concatenate_39[0][0]             \n",
            "                                                                 conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 8, 8, 258)    1032        concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 8, 8, 258)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 48)     12432       activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 8, 8, 48)     192         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 8, 8, 48)     0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 12)     5184        activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 8, 8, 270)    0           concatenate_40[0][0]             \n",
            "                                                                 conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 8, 8, 270)    1080        concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 270)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 8, 8, 48)     13008       activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 8, 8, 48)     192         conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 48)     0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 8, 8, 12)     5184        activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_42 (Concatenate)    (None, 8, 8, 282)    0           concatenate_41[0][0]             \n",
            "                                                                 conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 8, 8, 282)    1128        concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 282)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 48)     13584       activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 48)     192         conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 48)     0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 12)     5184        activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 8, 8, 294)    0           concatenate_42[0][0]             \n",
            "                                                                 conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 294)    1176        concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 8, 8, 294)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 48)     14160       activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 8, 8, 48)     192         conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 8, 8, 48)     0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 8, 8, 12)     5184        activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 8, 8, 306)    0           concatenate_43[0][0]             \n",
            "                                                                 conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 8, 8, 306)    1224        concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 8, 8, 306)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 8, 8, 48)     14736       activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 8, 8, 48)     192         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 8, 8, 48)     0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 8, 8, 12)     5184        activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 8, 8, 318)    0           concatenate_44[0][0]             \n",
            "                                                                 conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 8, 8, 318)    1272        concatenate_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 8, 8, 318)    0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 8, 8, 48)     15312       activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 8, 8, 48)     192         conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 8, 8, 48)     0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 8, 8, 12)     5184        activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_46 (Concatenate)    (None, 8, 8, 330)    0           concatenate_45[0][0]             \n",
            "                                                                 conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 8, 8, 330)    1320        concatenate_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 8, 8, 330)    0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 8, 8, 48)     15888       activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 8, 8, 48)     192         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 8, 8, 48)     0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 8, 8, 12)     5184        activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_47 (Concatenate)    (None, 8, 8, 342)    0           concatenate_46[0][0]             \n",
            "                                                                 conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 342)          0           concatenate_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           3430        global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 794,098\n",
            "Trainable params: 770,788\n",
            "Non-trainable params: 23,310\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ckmx1awZ-O7b",
        "colab_type": "code",
        "outputId": "c8cd5712-4cc6-4089-bfdc-b0a591ccf31f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# DenseNet-BC setup\n",
        "\n",
        "## input images 32 x 32\n",
        "inputs = keras.Input(img_dim)\n",
        "\n",
        "## call DenseNet-BC-100-12 without data augmentation with dropout rate of 0.2\n",
        "dropout_rate = 0.2\n",
        "outputs = DenseNet(inputs,init_nb_filters,growth_rate,nb_layers,theta,dropout_rate,weight_decay)\n",
        "\n",
        "## assign the actual model\n",
        "model = keras.Model(inputs,outputs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTC1xMPl-O9m",
        "colab_type": "code",
        "outputId": "ea49a7d9-ec58-4281-9fb9-3eba32041198",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 3)    12          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 3)    0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 24)   648         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 24)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 24)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 48)   1200        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 48)   192         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 48)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 12)   5184        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 36)   0           conv2d[0][0]                     \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 36)   144         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 36)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 48)   1776        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 48)   192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 48)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 12)   5184        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 48)   0           concatenate[0][0]                \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 48)   192         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 48)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 48)   2352        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 48)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 12)   5184        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 60)   0           concatenate_1[0][0]              \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 60)   240         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 60)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 48)   2928        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 48)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 48)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 12)   5184        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 72)   0           concatenate_2[0][0]              \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 72)   288         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 72)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 48)   3504        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 48)   192         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 48)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 12)   5184        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 84)   0           concatenate_3[0][0]              \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 84)   336         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 84)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 48)   4080        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 48)   192         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 48)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 12)   5184        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 96)   0           concatenate_4[0][0]              \n",
            "                                                                 conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 96)   384         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 96)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 48)   4656        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 48)   192         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 32, 48)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 12)   5184        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 108)  0           concatenate_5[0][0]              \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 32, 108)  432         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 32, 32, 108)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 48)   5232        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 32, 32, 48)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 32, 32, 48)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 12)   5184        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 32, 32, 120)  0           concatenate_6[0][0]              \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 32, 32, 120)  480         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 32, 32, 120)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 48)   5808        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 32, 32, 48)   192         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 32, 32, 48)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 12)   5184        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 132)  0           concatenate_7[0][0]              \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 32, 32, 132)  528         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 32, 32, 132)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 48)   6384        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 32, 32, 48)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 32, 32, 12)   5184        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 32, 144)  0           concatenate_8[0][0]              \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 32, 32, 144)  576         concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 32, 32, 144)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 32, 32, 48)   6960        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 32, 32, 48)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 32, 32, 48)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 32, 32, 12)   5184        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 32, 32, 156)  0           concatenate_9[0][0]              \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 32, 32, 156)  624         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 32, 32, 156)  0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 32, 32, 48)   7536        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 32, 32, 48)   192         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 32, 32, 48)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 32, 32, 12)   5184        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 32, 32, 168)  0           concatenate_10[0][0]             \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 32, 32, 168)  672         concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 32, 32, 168)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 32, 32, 48)   8112        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 32, 32, 48)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 32, 32, 48)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 32, 32, 12)   5184        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 32, 32, 180)  0           concatenate_11[0][0]             \n",
            "                                                                 conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 32, 32, 180)  720         concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 32, 32, 180)  0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 32, 32, 48)   8688        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 32, 32, 48)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 32, 32, 48)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 32, 32, 12)   5184        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 32, 32, 192)  0           concatenate_12[0][0]             \n",
            "                                                                 conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 32, 32, 192)  768         concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 32, 32, 192)  0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 32, 32, 48)   9264        activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 32, 32, 48)   192         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 32, 32, 48)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 32, 32, 12)   5184        activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 32, 32, 204)  0           concatenate_13[0][0]             \n",
            "                                                                 conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 32, 32, 204)  816         concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 32, 32, 204)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 32, 32, 48)   9840        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 32, 32, 48)   192         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 32, 32, 48)   0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 32, 32, 12)   5184        activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 32, 32, 216)  0           concatenate_14[0][0]             \n",
            "                                                                 conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 32, 32, 216)  864         concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 32, 32, 216)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 32, 32, 108)  23328       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 32, 32, 108)  0           conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 108)  0           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 16, 16, 108)  432         average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 16, 16, 108)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 16, 16, 48)   5232        activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 16, 16, 48)   192         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 16, 16, 48)   0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 16, 16, 12)   5184        activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 16, 16, 120)  0           average_pooling2d[0][0]          \n",
            "                                                                 conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 16, 16, 120)  480         concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 16, 16, 120)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 16, 16, 48)   5808        activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 16, 16, 48)   192         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 16, 16, 48)   0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 16, 16, 12)   5184        activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 16, 16, 132)  0           concatenate_16[0][0]             \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 16, 16, 132)  528         concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 16, 16, 132)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 16, 16, 48)   6384        activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 16, 16, 48)   192         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 16, 16, 48)   0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 16, 16, 12)   5184        activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 16, 16, 144)  0           concatenate_17[0][0]             \n",
            "                                                                 conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 16, 16, 144)  576         concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 16, 16, 144)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 16, 16, 48)   6960        activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 16, 16, 48)   192         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 16, 16, 48)   0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 16, 16, 12)   5184        activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 16, 16, 156)  0           concatenate_18[0][0]             \n",
            "                                                                 conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 16, 16, 156)  624         concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 16, 16, 156)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 16, 16, 48)   7536        activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 16, 16, 48)   192         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 16, 16, 48)   0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 16, 16, 12)   5184        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 16, 16, 168)  0           concatenate_19[0][0]             \n",
            "                                                                 conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 16, 16, 168)  672         concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 16, 16, 168)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 16, 16, 48)   8112        activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 16, 16, 48)   192         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 16, 16, 48)   0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 16, 16, 12)   5184        activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 16, 16, 180)  0           concatenate_20[0][0]             \n",
            "                                                                 conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 16, 16, 180)  720         concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 16, 16, 180)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 16, 16, 48)   8688        activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 16, 16, 48)   192         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 16, 16, 48)   0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 16, 16, 12)   5184        activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 16, 16, 192)  0           concatenate_21[0][0]             \n",
            "                                                                 conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 16, 16, 192)  768         concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 16, 16, 192)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 16, 16, 48)   9264        activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 16, 16, 48)   192         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 16, 16, 48)   0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 16, 16, 12)   5184        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 16, 16, 204)  0           concatenate_22[0][0]             \n",
            "                                                                 conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 16, 16, 204)  816         concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 16, 16, 204)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 16, 16, 48)   9840        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 16, 16, 48)   192         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 16, 16, 48)   0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 16, 16, 12)   5184        activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 16, 16, 216)  0           concatenate_23[0][0]             \n",
            "                                                                 conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 16, 16, 216)  864         concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 16, 16, 216)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 16, 16, 48)   10416       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 16, 16, 48)   192         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 16, 16, 48)   0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 16, 16, 12)   5184        activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 16, 16, 228)  0           concatenate_24[0][0]             \n",
            "                                                                 conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 16, 16, 228)  912         concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 16, 16, 228)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 16, 16, 48)   10992       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 16, 16, 48)   192         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 16, 16, 48)   0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 16, 16, 12)   5184        activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 16, 16, 240)  0           concatenate_25[0][0]             \n",
            "                                                                 conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 16, 16, 240)  960         concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 16, 16, 240)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 16, 16, 48)   11568       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 16, 16, 48)   192         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 16, 16, 48)   0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 16, 16, 12)   5184        activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 16, 16, 252)  0           concatenate_26[0][0]             \n",
            "                                                                 conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 16, 16, 252)  1008        concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 16, 16, 252)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 16, 16, 48)   12144       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 16, 16, 48)   192         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 16, 16, 48)   0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 16, 16, 12)   5184        activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 16, 16, 264)  0           concatenate_27[0][0]             \n",
            "                                                                 conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 16, 16, 264)  1056        concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 16, 16, 264)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 16, 16, 48)   12720       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 16, 16, 48)   192         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 16, 16, 48)   0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 16, 16, 12)   5184        activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 16, 16, 276)  0           concatenate_28[0][0]             \n",
            "                                                                 conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 16, 16, 276)  1104        concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 16, 16, 276)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 16, 16, 48)   13296       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 16, 16, 48)   192         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 16, 16, 48)   0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 16, 16, 12)   5184        activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 16, 16, 288)  0           concatenate_29[0][0]             \n",
            "                                                                 conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 16, 16, 288)  1152        concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 16, 16, 288)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 16, 16, 48)   13872       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 16, 16, 48)   192         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 16, 16, 48)   0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 16, 16, 12)   5184        activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 16, 16, 300)  0           concatenate_30[0][0]             \n",
            "                                                                 conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 16, 16, 300)  1200        concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 16, 16, 300)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 16, 16, 150)  45000       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 16, 16, 150)  0           conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 8, 8, 150)    0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 8, 8, 150)    600         average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 8, 8, 150)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 8, 8, 48)     7248        activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 8, 8, 48)     192         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 8, 8, 48)     0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 8, 8, 12)     5184        activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 8, 8, 162)    0           average_pooling2d_1[0][0]        \n",
            "                                                                 conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 8, 8, 162)    648         concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 8, 8, 162)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 8, 8, 48)     7824        activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 8, 8, 48)     192         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 8, 8, 48)     0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 8, 8, 12)     5184        activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 8, 8, 174)    0           concatenate_32[0][0]             \n",
            "                                                                 conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 8, 8, 174)    696         concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 174)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 8, 8, 48)     8400        activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 8, 8, 48)     192         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 8, 8, 48)     0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 8, 8, 12)     5184        activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 8, 8, 186)    0           concatenate_33[0][0]             \n",
            "                                                                 conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 8, 8, 186)    744         concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 8, 8, 186)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 8, 8, 48)     8976        activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 8, 8, 48)     192         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 8, 8, 48)     0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 8, 8, 12)     5184        activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 8, 8, 198)    0           concatenate_34[0][0]             \n",
            "                                                                 conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 8, 8, 198)    792         concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 8, 8, 198)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 8, 8, 48)     9552        activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 8, 8, 48)     192         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 48)     0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 12)     5184        activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 8, 8, 210)    0           concatenate_35[0][0]             \n",
            "                                                                 conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 8, 8, 210)    840         concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 210)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 48)     10128       activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 8, 8, 48)     192         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 8, 8, 48)     0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 12)     5184        activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 8, 8, 222)    0           concatenate_36[0][0]             \n",
            "                                                                 conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 8, 8, 222)    888         concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 8, 8, 222)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 48)     10704       activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 8, 8, 48)     192         conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 8, 8, 48)     0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 12)     5184        activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 8, 8, 234)    0           concatenate_37[0][0]             \n",
            "                                                                 conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 8, 8, 234)    936         concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 8, 8, 234)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 48)     11280       activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 8, 8, 48)     192         conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 8, 8, 48)     0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 12)     5184        activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 8, 8, 246)    0           concatenate_38[0][0]             \n",
            "                                                                 conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 8, 8, 246)    984         concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 8, 8, 246)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 48)     11856       activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 8, 8, 48)     192         conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 8, 8, 48)     0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 12)     5184        activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 8, 8, 258)    0           concatenate_39[0][0]             \n",
            "                                                                 conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 8, 8, 258)    1032        concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 8, 8, 258)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 48)     12432       activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 8, 8, 48)     192         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 8, 8, 48)     0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 12)     5184        activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 8, 8, 270)    0           concatenate_40[0][0]             \n",
            "                                                                 conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 8, 8, 270)    1080        concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 270)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 8, 8, 48)     13008       activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 8, 8, 48)     192         conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 48)     0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 8, 8, 12)     5184        activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_42 (Concatenate)    (None, 8, 8, 282)    0           concatenate_41[0][0]             \n",
            "                                                                 conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 8, 8, 282)    1128        concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 282)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 48)     13584       activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 48)     192         conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 48)     0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 12)     5184        activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 8, 8, 294)    0           concatenate_42[0][0]             \n",
            "                                                                 conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 294)    1176        concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 8, 8, 294)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 48)     14160       activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 8, 8, 48)     192         conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 8, 8, 48)     0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 8, 8, 12)     5184        activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 8, 8, 306)    0           concatenate_43[0][0]             \n",
            "                                                                 conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 8, 8, 306)    1224        concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 8, 8, 306)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 8, 8, 48)     14736       activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 8, 8, 48)     192         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 8, 8, 48)     0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 8, 8, 12)     5184        activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 8, 8, 318)    0           concatenate_44[0][0]             \n",
            "                                                                 conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 8, 8, 318)    1272        concatenate_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 8, 8, 318)    0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 8, 8, 48)     15312       activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 8, 8, 48)     192         conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 8, 8, 48)     0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 8, 8, 12)     5184        activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_46 (Concatenate)    (None, 8, 8, 330)    0           concatenate_45[0][0]             \n",
            "                                                                 conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 8, 8, 330)    1320        concatenate_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 8, 8, 330)    0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 8, 8, 48)     15888       activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 8, 8, 48)     192         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 8, 8, 48)     0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 8, 8, 12)     5184        activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_47 (Concatenate)    (None, 8, 8, 342)    0           concatenate_46[0][0]             \n",
            "                                                                 conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 342)          0           concatenate_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           3430        global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 794,098\n",
            "Trainable params: 770,788\n",
            "Non-trainable params: 23,310\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYYFMK4-1nCh",
        "colab_type": "text"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU8iR5KEzxYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training parameters\n",
        "## define learning rate decay rule\n",
        "def scheduler(epoch):\n",
        "    \"\"\"learning rate decay for 40 epoch\n",
        "    - 50% of epoch: 0.1 \n",
        "    50% -75% of epoch: 0.01 \n",
        "    70% - of epoch: 0.001\n",
        "    \"\"\"\n",
        "    if epoch < 20:\n",
        "        return 0.1\n",
        "    if epoch < 30:\n",
        "        return 0.01\n",
        "    return 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SricOUEKsxGH",
        "colab_type": "code",
        "outputId": "7095aed2-1816-4b3f-9750-1a8e5a009933",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# actual training \n",
        "## define optimizer:SGD \n",
        "optimizer = keras.optimizers.SGD(lr=.1, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
        "\n",
        "## define callbacks\n",
        "model_checkpoint = keras.callbacks.ModelCheckpoint('densenet_100_12.h5', monitor=\"val_acc\", save_best_only=True,\n",
        "                                  save_weights_only=True, verbose=1)\n",
        "\n",
        "## set callback\n",
        "change_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
        "callbacks = [change_lr,model_checkpoint]\n",
        "\n",
        "## feed all settings into the model to train\n",
        "history = model.fit_generator(generator=train_datagen,\n",
        "                steps_per_epoch= x_tr.shape[0] // batch_size,\n",
        "                epochs=nb_epoch,b\n",
        "                callbacks=callbacks,\n",
        "                validation_data=validation_datagen,\n",
        "                validation_steps = x_val.shape[0] // batch_size,\n",
        "                verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 1.7252 - acc: 0.4417Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:33 - loss: 2.1011 - acc: 0.3602\n",
            "Epoch 00001: val_acc improved from -inf to 0.36018, saving model to densenet_100_12.h5\n",
            "703/703 [==============================] - 401s 570ms/step - loss: 1.7246 - acc: 0.4419 - val_loss: 2.1011 - val_acc: 0.3602\n",
            "Epoch 2/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 1.1473 - acc: 0.6548Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:14 - loss: 1.3462 - acc: 0.6024\n",
            "Epoch 00002: val_acc improved from 0.36018 to 0.60236, saving model to densenet_100_12.h5\n",
            "703/703 [==============================] - 319s 454ms/step - loss: 1.1469 - acc: 0.6549 - val_loss: 1.3462 - val_acc: 0.6024\n",
            "Epoch 3/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.9270 - acc: 0.7358Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:14 - loss: 1.3593 - acc: 0.6274\n",
            "Epoch 00003: val_acc improved from 0.60236 to 0.62740, saving model to densenet_100_12.h5\n",
            "703/703 [==============================] - 318s 453ms/step - loss: 0.9271 - acc: 0.7358 - val_loss: 1.3593 - val_acc: 0.6274\n",
            "Epoch 4/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.8090 - acc: 0.7783Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:14 - loss: 1.0955 - acc: 0.7049\n",
            "Epoch 00004: val_acc improved from 0.62740 to 0.70493, saving model to densenet_100_12.h5\n",
            "703/703 [==============================] - 317s 451ms/step - loss: 0.8091 - acc: 0.7783 - val_loss: 1.0955 - val_acc: 0.7049\n",
            "Epoch 5/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.7311 - acc: 0.8072Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:14 - loss: 0.9678 - acc: 0.7252\n",
            "Epoch 00005: val_acc improved from 0.70493 to 0.72516, saving model to densenet_100_12.h5\n",
            "703/703 [==============================] - 317s 451ms/step - loss: 0.7310 - acc: 0.8072 - val_loss: 0.9678 - val_acc: 0.7252\n",
            "Epoch 6/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.6824 - acc: 0.8232Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:14 - loss: 1.2090 - acc: 0.6945\n",
            "Epoch 00006: val_acc did not improve from 0.72516\n",
            "703/703 [==============================] - 318s 452ms/step - loss: 0.6826 - acc: 0.8232 - val_loss: 1.2090 - val_acc: 0.6945\n",
            "Epoch 7/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.6531 - acc: 0.8323Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:14 - loss: 0.7011 - acc: 0.8193\n",
            "Epoch 00007: val_acc improved from 0.72516 to 0.81931, saving model to densenet_100_12.h5\n",
            "703/703 [==============================] - 318s 453ms/step - loss: 0.6530 - acc: 0.8323 - val_loss: 0.7011 - val_acc: 0.8193\n",
            "Epoch 8/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.6235 - acc: 0.8435Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:14 - loss: 0.6554 - acc: 0.8347\n",
            "Epoch 00008: val_acc improved from 0.81931 to 0.83474, saving model to densenet_100_12.h5\n",
            "703/703 [==============================] - 319s 454ms/step - loss: 0.6237 - acc: 0.8434 - val_loss: 0.6554 - val_acc: 0.8347\n",
            "Epoch 9/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.6031 - acc: 0.8513Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:13 - loss: 0.8741 - acc: 0.7720\n",
            "Epoch 00009: val_acc did not improve from 0.83474\n",
            "703/703 [==============================] - 318s 452ms/step - loss: 0.6031 - acc: 0.8513 - val_loss: 0.8741 - val_acc: 0.7720\n",
            "Epoch 10/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.5872 - acc: 0.8573Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:13 - loss: 0.8564 - acc: 0.7770\n",
            "Epoch 00010: val_acc did not improve from 0.83474\n",
            "703/703 [==============================] - 318s 452ms/step - loss: 0.5871 - acc: 0.8573 - val_loss: 0.8564 - val_acc: 0.7770\n",
            "Epoch 11/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.5656 - acc: 0.8640Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:13 - loss: 0.9601 - acc: 0.7588\n",
            "Epoch 00011: val_acc did not improve from 0.83474\n",
            "703/703 [==============================] - 318s 452ms/step - loss: 0.5658 - acc: 0.8639 - val_loss: 0.9601 - val_acc: 0.7588\n",
            "Epoch 12/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.5526 - acc: 0.8691Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:13 - loss: 0.5628 - acc: 0.8664\n",
            "Epoch 00012: val_acc improved from 0.83474 to 0.86639, saving model to densenet_100_12.h5\n",
            "703/703 [==============================] - 319s 453ms/step - loss: 0.5525 - acc: 0.8691 - val_loss: 0.5628 - val_acc: 0.8664\n",
            "Epoch 13/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.5360 - acc: 0.8748Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:13 - loss: 0.5729 - acc: 0.8638\n",
            "Epoch 00013: val_acc did not improve from 0.86639\n",
            "703/703 [==============================] - 318s 453ms/step - loss: 0.5359 - acc: 0.8748 - val_loss: 0.5729 - val_acc: 0.8638\n",
            "Epoch 14/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.5413 - acc: 0.8724Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:13 - loss: 0.8831 - acc: 0.7646\n",
            "Epoch 00014: val_acc did not improve from 0.86639\n",
            "703/703 [==============================] - 318s 452ms/step - loss: 0.5413 - acc: 0.8724 - val_loss: 0.8831 - val_acc: 0.7646\n",
            "Epoch 15/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.5219 - acc: 0.8812Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:13 - loss: 0.8471 - acc: 0.7744\n",
            "Epoch 00015: val_acc did not improve from 0.86639\n",
            "703/703 [==============================] - 318s 452ms/step - loss: 0.5218 - acc: 0.8812 - val_loss: 0.8471 - val_acc: 0.7744\n",
            "Epoch 16/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.5148 - acc: 0.8829Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:13 - loss: 0.6659 - acc: 0.8347\n",
            "Epoch 00016: val_acc did not improve from 0.86639\n",
            "703/703 [==============================] - 316s 450ms/step - loss: 0.5146 - acc: 0.8830 - val_loss: 0.6659 - val_acc: 0.8347\n",
            "Epoch 17/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.5116 - acc: 0.8844Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:14 - loss: 0.6125 - acc: 0.8524\n",
            "Epoch 00017: val_acc did not improve from 0.86639\n",
            "703/703 [==============================] - 316s 450ms/step - loss: 0.5114 - acc: 0.8845 - val_loss: 0.6125 - val_acc: 0.8524\n",
            "Epoch 18/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.5014 - acc: 0.8898Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:14 - loss: 0.7835 - acc: 0.8029\n",
            "Epoch 00018: val_acc did not improve from 0.86639\n",
            "703/703 [==============================] - 319s 454ms/step - loss: 0.5015 - acc: 0.8897 - val_loss: 0.7835 - val_acc: 0.8029\n",
            "Epoch 19/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.4998 - acc: 0.8889Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:14 - loss: 0.9312 - acc: 0.7708\n",
            "Epoch 00019: val_acc did not improve from 0.86639\n",
            "703/703 [==============================] - 319s 454ms/step - loss: 0.4999 - acc: 0.8888 - val_loss: 0.9312 - val_acc: 0.7708\n",
            "Epoch 20/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.4944 - acc: 0.8924Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:14 - loss: 0.6429 - acc: 0.8363\n",
            "Epoch 00020: val_acc did not improve from 0.86639\n",
            "703/703 [==============================] - 319s 454ms/step - loss: 0.4946 - acc: 0.8923 - val_loss: 0.6429 - val_acc: 0.8363\n",
            "Epoch 21/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.3846 - acc: 0.9299Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:15 - loss: 0.3300 - acc: 0.9447\n",
            "Epoch 00021: val_acc improved from 0.86639 to 0.94471, saving model to densenet_100_12.h5\n",
            "703/703 [==============================] - 319s 454ms/step - loss: 0.3847 - acc: 0.9299 - val_loss: 0.3300 - val_acc: 0.9447\n",
            "Epoch 22/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.3335 - acc: 0.9468Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:14 - loss: 0.3081 - acc: 0.9547\n",
            "Epoch 00022: val_acc improved from 0.94471 to 0.95473, saving model to densenet_100_12.h5\n",
            "703/703 [==============================] - 319s 454ms/step - loss: 0.3336 - acc: 0.9468 - val_loss: 0.3081 - val_acc: 0.9547\n",
            "Epoch 23/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.3121 - acc: 0.9523Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:14 - loss: 0.2936 - acc: 0.9577\n",
            "Epoch 00023: val_acc improved from 0.95473 to 0.95773, saving model to densenet_100_12.h5\n",
            "703/703 [==============================] - 320s 455ms/step - loss: 0.3121 - acc: 0.9523 - val_loss: 0.2936 - val_acc: 0.9577\n",
            "Epoch 24/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.3036 - acc: 0.9529Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:14 - loss: 0.2832 - acc: 0.9583\n",
            "Epoch 00024: val_acc improved from 0.95773 to 0.95833, saving model to densenet_100_12.h5\n",
            "703/703 [==============================] - 319s 453ms/step - loss: 0.3037 - acc: 0.9528 - val_loss: 0.2832 - val_acc: 0.9583\n",
            "Epoch 25/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.2918 - acc: 0.9562Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:14 - loss: 0.2671 - acc: 0.9629\n",
            "Epoch 00025: val_acc improved from 0.95833 to 0.96294, saving model to densenet_100_12.h5\n",
            "703/703 [==============================] - 320s 455ms/step - loss: 0.2917 - acc: 0.9563 - val_loss: 0.2671 - val_acc: 0.9629\n",
            "Epoch 26/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.2755 - acc: 0.9600Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:14 - loss: 0.2692 - acc: 0.9637\n",
            "Epoch 00026: val_acc improved from 0.96294 to 0.96374, saving model to densenet_100_12.h5\n",
            "703/703 [==============================] - 321s 457ms/step - loss: 0.2755 - acc: 0.9601 - val_loss: 0.2692 - val_acc: 0.9637\n",
            "Epoch 27/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.2712 - acc: 0.9605Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:14 - loss: 0.2737 - acc: 0.9581\n",
            "Epoch 00027: val_acc did not improve from 0.96374\n",
            "703/703 [==============================] - 321s 456ms/step - loss: 0.2713 - acc: 0.9604 - val_loss: 0.2737 - val_acc: 0.9581\n",
            "Epoch 28/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.2641 - acc: 0.9614Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:14 - loss: 0.2445 - acc: 0.9692\n",
            "Epoch 00028: val_acc improved from 0.96374 to 0.96915, saving model to densenet_100_12.h5\n",
            "703/703 [==============================] - 320s 456ms/step - loss: 0.2640 - acc: 0.9614 - val_loss: 0.2445 - val_acc: 0.9692\n",
            "Epoch 29/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.2550 - acc: 0.9634Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:14 - loss: 0.2387 - acc: 0.9706\n",
            "Epoch 00029: val_acc improved from 0.96915 to 0.97055, saving model to densenet_100_12.h5\n",
            "703/703 [==============================] - 320s 456ms/step - loss: 0.2550 - acc: 0.9634 - val_loss: 0.2387 - val_acc: 0.9706\n",
            "Epoch 30/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.2473 - acc: 0.9669Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:14 - loss: 0.2312 - acc: 0.9724\n",
            "Epoch 00030: val_acc improved from 0.97055 to 0.97236, saving model to densenet_100_12.h5\n",
            "703/703 [==============================] - 321s 457ms/step - loss: 0.2473 - acc: 0.9669 - val_loss: 0.2312 - val_acc: 0.9724\n",
            "Epoch 31/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.2339 - acc: 0.9702Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:14 - loss: 0.2170 - acc: 0.9788\n",
            "Epoch 00031: val_acc improved from 0.97236 to 0.97877, saving model to densenet_100_12.h5\n",
            "703/703 [==============================] - 321s 457ms/step - loss: 0.2339 - acc: 0.9701 - val_loss: 0.2170 - val_acc: 0.9788\n",
            "Epoch 32/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.2264 - acc: 0.9727Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:14 - loss: 0.2139 - acc: 0.9790\n",
            "Epoch 00032: val_acc improved from 0.97877 to 0.97897, saving model to densenet_100_12.h5\n",
            "703/703 [==============================] - 321s 457ms/step - loss: 0.2264 - acc: 0.9727 - val_loss: 0.2139 - val_acc: 0.9790\n",
            "Epoch 33/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.2256 - acc: 0.9723Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:14 - loss: 0.2112 - acc: 0.9796\n",
            "Epoch 00033: val_acc improved from 0.97897 to 0.97957, saving model to densenet_100_12.h5\n",
            "703/703 [==============================] - 321s 456ms/step - loss: 0.2257 - acc: 0.9723 - val_loss: 0.2112 - val_acc: 0.9796\n",
            "Epoch 34/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.2263 - acc: 0.9734Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:14 - loss: 0.2120 - acc: 0.9786\n",
            "Epoch 00034: val_acc did not improve from 0.97957\n",
            "703/703 [==============================] - 318s 453ms/step - loss: 0.2264 - acc: 0.9733 - val_loss: 0.2120 - val_acc: 0.9786\n",
            "Epoch 35/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.2238 - acc: 0.9732Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:13 - loss: 0.2095 - acc: 0.9804\n",
            "Epoch 00035: val_acc improved from 0.97957 to 0.98037, saving model to densenet_100_12.h5\n",
            "703/703 [==============================] - 319s 454ms/step - loss: 0.2237 - acc: 0.9733 - val_loss: 0.2095 - val_acc: 0.9804\n",
            "Epoch 36/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.2227 - acc: 0.9740Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:14 - loss: 0.2098 - acc: 0.9802\n",
            "Epoch 00036: val_acc did not improve from 0.98037\n",
            "703/703 [==============================] - 319s 453ms/step - loss: 0.2227 - acc: 0.9739 - val_loss: 0.2098 - val_acc: 0.9802\n",
            "Epoch 37/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.2208 - acc: 0.9740Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:13 - loss: 0.2069 - acc: 0.9804\n",
            "Epoch 00037: val_acc did not improve from 0.98037\n",
            "703/703 [==============================] - 318s 453ms/step - loss: 0.2208 - acc: 0.9740 - val_loss: 0.2069 - val_acc: 0.9804\n",
            "Epoch 38/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.2197 - acc: 0.9741Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:14 - loss: 0.2072 - acc: 0.9806\n",
            "Epoch 00038: val_acc improved from 0.98037 to 0.98057, saving model to densenet_100_12.h5\n",
            "703/703 [==============================] - 319s 454ms/step - loss: 0.2196 - acc: 0.9741 - val_loss: 0.2072 - val_acc: 0.9806\n",
            "Epoch 39/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.2185 - acc: 0.9751Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:13 - loss: 0.2056 - acc: 0.9812\n",
            "Epoch 00039: val_acc improved from 0.98057 to 0.98117, saving model to densenet_100_12.h5\n",
            "703/703 [==============================] - 319s 453ms/step - loss: 0.2185 - acc: 0.9751 - val_loss: 0.2056 - val_acc: 0.9812\n",
            "Epoch 40/40\n",
            "702/703 [============================>.] - ETA: 0s - loss: 0.2183 - acc: 0.9744Epoch 1/40\n",
            " 78/703 [==>...........................] - ETA: 1:13 - loss: 0.2027 - acc: 0.9812\n",
            "Epoch 00040: val_acc did not improve from 0.98117\n",
            "703/703 [==============================] - 317s 451ms/step - loss: 0.2183 - acc: 0.9745 - val_loss: 0.2027 - val_acc: 0.9812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Tm5rlIVXG8v",
        "colab_type": "code",
        "outputId": "96c05f7d-f77f-48eb-bb7a-96344ae32150",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# actual training \n",
        "## define optimizer:SGD \n",
        "optimizer = keras.optimizers.SGD(lr=.1, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
        "\n",
        "## define callbacks\n",
        "model_checkpoint = keras.callbacks.ModelCheckpoint('densenet_100_12_dropout.h5', monitor=\"val_acc\", save_best_only=True,\n",
        "                                  save_weights_only=True, verbose=1)\n",
        "\n",
        "## set callback\n",
        "change_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
        "callbacks = [change_lr,model_checkpoint]\n",
        "\n",
        "## feed all settings into the model to train\n",
        "history = model.fit(x_tr,y_tr,\n",
        "                   epochs=nb_epoch,\n",
        "                   callbacks=callbacks,\n",
        "                    validation_data = (x_val,y_val),\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 1.7691 - acc: 0.4161\n",
            "Epoch 00001: val_acc improved from -inf to 0.41380, saving model to densenet_100_12_dropout.h5\n",
            "45000/45000 [==============================] - 429s 10ms/sample - loss: 1.7691 - acc: 0.4161 - val_loss: 2.1730 - val_acc: 0.4138\n",
            "Epoch 2/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 1.2433 - acc: 0.6150\n",
            "Epoch 00002: val_acc improved from 0.41380 to 0.55180, saving model to densenet_100_12_dropout.h5\n",
            "45000/45000 [==============================] - 344s 8ms/sample - loss: 1.2434 - acc: 0.6150 - val_loss: 1.5310 - val_acc: 0.5518\n",
            "Epoch 3/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 1.0171 - acc: 0.7027\n",
            "Epoch 00003: val_acc improved from 0.55180 to 0.64040, saving model to densenet_100_12_dropout.h5\n",
            "45000/45000 [==============================] - 344s 8ms/sample - loss: 1.0171 - acc: 0.7027 - val_loss: 1.2309 - val_acc: 0.6404\n",
            "Epoch 4/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.8916 - acc: 0.7536\n",
            "Epoch 00004: val_acc improved from 0.64040 to 0.65780, saving model to densenet_100_12_dropout.h5\n",
            "45000/45000 [==============================] - 344s 8ms/sample - loss: 0.8916 - acc: 0.7536 - val_loss: 1.2839 - val_acc: 0.6578\n",
            "Epoch 5/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.8148 - acc: 0.7831\n",
            "Epoch 00005: val_acc improved from 0.65780 to 0.70320, saving model to densenet_100_12_dropout.h5\n",
            "45000/45000 [==============================] - 344s 8ms/sample - loss: 0.8149 - acc: 0.7830 - val_loss: 1.0872 - val_acc: 0.7032\n",
            "Epoch 6/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.7780 - acc: 0.8010\n",
            "Epoch 00006: val_acc did not improve from 0.70320\n",
            "45000/45000 [==============================] - 344s 8ms/sample - loss: 0.7780 - acc: 0.8010 - val_loss: 1.4105 - val_acc: 0.6354\n",
            "Epoch 7/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.7428 - acc: 0.8138\n",
            "Epoch 00007: val_acc improved from 0.70320 to 0.73460, saving model to densenet_100_12_dropout.h5\n",
            "45000/45000 [==============================] - 345s 8ms/sample - loss: 0.7430 - acc: 0.8138 - val_loss: 1.0168 - val_acc: 0.7346\n",
            "Epoch 8/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.7137 - acc: 0.8255\n",
            "Epoch 00008: val_acc improved from 0.73460 to 0.74540, saving model to densenet_100_12_dropout.h5\n",
            "45000/45000 [==============================] - 344s 8ms/sample - loss: 0.7138 - acc: 0.8254 - val_loss: 0.9637 - val_acc: 0.7454\n",
            "Epoch 9/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.7027 - acc: 0.8314\n",
            "Epoch 00009: val_acc did not improve from 0.74540\n",
            "45000/45000 [==============================] - 344s 8ms/sample - loss: 0.7028 - acc: 0.8314 - val_loss: 1.2724 - val_acc: 0.6944\n",
            "Epoch 10/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.6828 - acc: 0.8407\n",
            "Epoch 00010: val_acc did not improve from 0.74540\n",
            "45000/45000 [==============================] - 343s 8ms/sample - loss: 0.6828 - acc: 0.8408 - val_loss: 1.4364 - val_acc: 0.6616\n",
            "Epoch 11/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.6725 - acc: 0.8459\n",
            "Epoch 00011: val_acc improved from 0.74540 to 0.74620, saving model to densenet_100_12_dropout.h5\n",
            "45000/45000 [==============================] - 344s 8ms/sample - loss: 0.6725 - acc: 0.8459 - val_loss: 1.0172 - val_acc: 0.7462\n",
            "Epoch 12/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.6623 - acc: 0.8507\n",
            "Epoch 00012: val_acc improved from 0.74620 to 0.75480, saving model to densenet_100_12_dropout.h5\n",
            "45000/45000 [==============================] - 345s 8ms/sample - loss: 0.6623 - acc: 0.8507 - val_loss: 0.9784 - val_acc: 0.7548\n",
            "Epoch 13/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.6482 - acc: 0.8593\n",
            "Epoch 00013: val_acc improved from 0.75480 to 0.80200, saving model to densenet_100_12_dropout.h5\n",
            "45000/45000 [==============================] - 343s 8ms/sample - loss: 0.6482 - acc: 0.8593 - val_loss: 0.8593 - val_acc: 0.8020\n",
            "Epoch 14/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.6466 - acc: 0.8584\n",
            "Epoch 00014: val_acc did not improve from 0.80200\n",
            "45000/45000 [==============================] - 344s 8ms/sample - loss: 0.6465 - acc: 0.8585 - val_loss: 0.8696 - val_acc: 0.7922\n",
            "Epoch 15/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.6333 - acc: 0.8670\n",
            "Epoch 00015: val_acc did not improve from 0.80200\n",
            "45000/45000 [==============================] - 344s 8ms/sample - loss: 0.6333 - acc: 0.8670 - val_loss: 0.9847 - val_acc: 0.7614\n",
            "Epoch 16/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.6268 - acc: 0.8685\n",
            "Epoch 00016: val_acc did not improve from 0.80200\n",
            "45000/45000 [==============================] - 346s 8ms/sample - loss: 0.6268 - acc: 0.8685 - val_loss: 0.9601 - val_acc: 0.7758\n",
            "Epoch 17/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.6204 - acc: 0.8702\n",
            "Epoch 00017: val_acc improved from 0.80200 to 0.81000, saving model to densenet_100_12_dropout.h5\n",
            "45000/45000 [==============================] - 347s 8ms/sample - loss: 0.6204 - acc: 0.8702 - val_loss: 0.7992 - val_acc: 0.8100\n",
            "Epoch 18/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.6188 - acc: 0.8722\n",
            "Epoch 00018: val_acc did not improve from 0.81000\n",
            "45000/45000 [==============================] - 346s 8ms/sample - loss: 0.6188 - acc: 0.8722 - val_loss: 1.0585 - val_acc: 0.7572\n",
            "Epoch 19/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.6165 - acc: 0.8755\n",
            "Epoch 00019: val_acc did not improve from 0.81000\n",
            "45000/45000 [==============================] - 347s 8ms/sample - loss: 0.6165 - acc: 0.8755 - val_loss: 1.0247 - val_acc: 0.7630\n",
            "Epoch 20/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.6074 - acc: 0.8787\n",
            "Epoch 00020: val_acc did not improve from 0.81000\n",
            "45000/45000 [==============================] - 346s 8ms/sample - loss: 0.6073 - acc: 0.8787 - val_loss: 0.9597 - val_acc: 0.7712\n",
            "Epoch 21/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.4328 - acc: 0.9382\n",
            "Epoch 00021: val_acc improved from 0.81000 to 0.89700, saving model to densenet_100_12_dropout.h5\n",
            "45000/45000 [==============================] - 347s 8ms/sample - loss: 0.4328 - acc: 0.9382 - val_loss: 0.5769 - val_acc: 0.8970\n",
            "Epoch 22/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.3578 - acc: 0.9613\n",
            "Epoch 00022: val_acc improved from 0.89700 to 0.90320, saving model to densenet_100_12_dropout.h5\n",
            "45000/45000 [==============================] - 347s 8ms/sample - loss: 0.3579 - acc: 0.9613 - val_loss: 0.5816 - val_acc: 0.9032\n",
            "Epoch 23/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.3224 - acc: 0.9700\n",
            "Epoch 00023: val_acc did not improve from 0.90320\n",
            "45000/45000 [==============================] - 344s 8ms/sample - loss: 0.3224 - acc: 0.9700 - val_loss: 0.5700 - val_acc: 0.9004\n",
            "Epoch 24/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.2970 - acc: 0.9749\n",
            "Epoch 00024: val_acc did not improve from 0.90320\n",
            "45000/45000 [==============================] - 343s 8ms/sample - loss: 0.2970 - acc: 0.9749 - val_loss: 0.5872 - val_acc: 0.8970\n",
            "Epoch 25/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.2730 - acc: 0.9802\n",
            "Epoch 00025: val_acc did not improve from 0.90320\n",
            "45000/45000 [==============================] - 344s 8ms/sample - loss: 0.2731 - acc: 0.9802 - val_loss: 0.5871 - val_acc: 0.8986\n",
            "Epoch 26/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.2530 - acc: 0.9845\n",
            "Epoch 00026: val_acc did not improve from 0.90320\n",
            "45000/45000 [==============================] - 344s 8ms/sample - loss: 0.2531 - acc: 0.9845 - val_loss: 0.6182 - val_acc: 0.8948\n",
            "Epoch 27/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.2367 - acc: 0.9866\n",
            "Epoch 00027: val_acc did not improve from 0.90320\n",
            "45000/45000 [==============================] - 343s 8ms/sample - loss: 0.2367 - acc: 0.9866 - val_loss: 0.6351 - val_acc: 0.8934\n",
            "Epoch 28/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.2240 - acc: 0.9885\n",
            "Epoch 00028: val_acc did not improve from 0.90320\n",
            "45000/45000 [==============================] - 344s 8ms/sample - loss: 0.2240 - acc: 0.9885 - val_loss: 0.6155 - val_acc: 0.8958\n",
            "Epoch 29/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.2115 - acc: 0.9904\n",
            "Epoch 00029: val_acc did not improve from 0.90320\n",
            "45000/45000 [==============================] - 344s 8ms/sample - loss: 0.2116 - acc: 0.9903 - val_loss: 0.6383 - val_acc: 0.8924\n",
            "Epoch 30/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.2017 - acc: 0.9913\n",
            "Epoch 00030: val_acc did not improve from 0.90320\n",
            "45000/45000 [==============================] - 344s 8ms/sample - loss: 0.2017 - acc: 0.9913 - val_loss: 0.6306 - val_acc: 0.8902\n",
            "Epoch 31/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.1911 - acc: 0.9937\n",
            "Epoch 00031: val_acc did not improve from 0.90320\n",
            "45000/45000 [==============================] - 343s 8ms/sample - loss: 0.1911 - acc: 0.9937 - val_loss: 0.5975 - val_acc: 0.8962\n",
            "Epoch 32/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.1856 - acc: 0.9951\n",
            "Epoch 00032: val_acc did not improve from 0.90320\n",
            "45000/45000 [==============================] - 343s 8ms/sample - loss: 0.1856 - acc: 0.9951 - val_loss: 0.5956 - val_acc: 0.8962\n",
            "Epoch 33/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.1839 - acc: 0.9961\n",
            "Epoch 00033: val_acc did not improve from 0.90320\n",
            "45000/45000 [==============================] - 344s 8ms/sample - loss: 0.1839 - acc: 0.9961 - val_loss: 0.5988 - val_acc: 0.8976\n",
            "Epoch 34/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.1801 - acc: 0.9968\n",
            "Epoch 00034: val_acc did not improve from 0.90320\n",
            "45000/45000 [==============================] - 345s 8ms/sample - loss: 0.1801 - acc: 0.9968 - val_loss: 0.5973 - val_acc: 0.8966\n",
            "Epoch 35/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.1804 - acc: 0.9960\n",
            "Epoch 00035: val_acc did not improve from 0.90320\n",
            "45000/45000 [==============================] - 344s 8ms/sample - loss: 0.1804 - acc: 0.9960 - val_loss: 0.6020 - val_acc: 0.8972\n",
            "Epoch 36/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.1785 - acc: 0.9967\n",
            "Epoch 00036: val_acc did not improve from 0.90320\n",
            "45000/45000 [==============================] - 344s 8ms/sample - loss: 0.1785 - acc: 0.9967 - val_loss: 0.5993 - val_acc: 0.8970\n",
            "Epoch 37/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.1769 - acc: 0.9969\n",
            "Epoch 00037: val_acc did not improve from 0.90320\n",
            "45000/45000 [==============================] - 347s 8ms/sample - loss: 0.1770 - acc: 0.9969 - val_loss: 0.6004 - val_acc: 0.8974\n",
            "Epoch 38/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.1757 - acc: 0.9972\n",
            "Epoch 00038: val_acc did not improve from 0.90320\n",
            "45000/45000 [==============================] - 347s 8ms/sample - loss: 0.1757 - acc: 0.9972 - val_loss: 0.6009 - val_acc: 0.8984\n",
            "Epoch 39/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.1741 - acc: 0.9977\n",
            "Epoch 00039: val_acc did not improve from 0.90320\n",
            "45000/45000 [==============================] - 347s 8ms/sample - loss: 0.1741 - acc: 0.9977 - val_loss: 0.6018 - val_acc: 0.8988\n",
            "Epoch 40/40\n",
            "44992/45000 [============================>.] - ETA: 0s - loss: 0.1733 - acc: 0.9976\n",
            "Epoch 00040: val_acc did not improve from 0.90320\n",
            "45000/45000 [==============================] - 347s 8ms/sample - loss: 0.1734 - acc: 0.9976 - val_loss: 0.6031 - val_acc: 0.8988\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiDDI3frCLeM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/trainHistory10012dropout', 'wb') as f:\n",
        "    pickle.dump(history.history, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olzMmTRZ5I3b",
        "colab_type": "text"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFuUgmCj6sQI",
        "colab_type": "text"
      },
      "source": [
        "## Model Evaluation on Testset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdJcxKPW6qdm",
        "colab_type": "code",
        "outputId": "13f7a09e-8c63-4f1f-f91f-26997534202e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# accuracy on test set using DenseNet-BC-100-12 with data augmentation\n",
        "accuracy_bc_100_12_aug = model.evaluate(x_test,y_test,batch_size)\n",
        "print(accuracy_bc_100_12_aug)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 18s 2ms/sample - loss: 0.4094 - acc: 0.9188\n",
            "[0.40941992235183716, 0.9188]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOwFmajL__AZ",
        "colab_type": "code",
        "outputId": "9a241ea1-d2f6-41ae-eb56-a0969c810ce4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# accuracy on test set using DenseNet-BC-100-12 without data augmentation\n",
        "accuracy_bc_100_12_dropout = model.evaluate(x_test,y_test,batch_size)\n",
        "print(accuracy_bc_100_12_dropout)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 19s 2ms/sample - loss: 0.6428 - acc: 0.8959\n",
            "[0.642806273841858, 0.8959]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ma246Q8-5MnF",
        "colab_type": "text"
      },
      "source": [
        "## Training and Validation Accuracy Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR9YO6CO2O_1",
        "colab_type": "code",
        "outputId": "346e12e6-a7b2-4ed7-9522-f413d648a909",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('DenseNet-BC-100-12 accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig('/model accuracy BC-100-12.png')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nw1e8AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTANZ5Zi0u4X",
        "colab_type": "code",
        "outputId": "4e15edca-0b7f-4876-a8c9-3a32b48c10d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('DenseNet-BC-100-12-dropout accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig('/model accuracy BC-100-12-dropout.png')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1UsP9k06Ujl",
        "colab_type": "text"
      },
      "source": [
        "## Training and Validation Loss Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVy-m-yd4VX0",
        "colab_type": "code",
        "outputId": "c2d1be0c-8341-4458-d2bc-776f7f6ee340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('DenseNet-BC-100-12 loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig('/model loss BC-100-12.png')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leRU2Gak01Lu",
        "colab_type": "code",
        "outputId": "53377d3c-1991-40d9-d4ee-9047f448d08d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('DenseNet-BC-100-12-dropout loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig('/model loss BC-100-12-dropout.png')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nO3ubemfiMqpWAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}